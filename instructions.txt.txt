Pulse AI Studio — Complete Cursor Build Instructions (Phased, AWS-First, IaC)

Context for Cursor
Repo: https://github.com/Samer-Is/pulse (empty at the moment — you must scaffold)
Constraints: Minimal AWS cost (use t3.micro/t4g.micro where possible), first-time AWS user, budget ~$120 credits, must be infra-as-code, no manual clicks beyond the necessary cloud console steps for credentials/domains.
Models:

Chat: OpenAI (GPT-4/5), Anthropic (Claude 3.5/4.x), Google (Gemini via Vertex AI)

Image: Google Vertex AI Imagen (user wrote “nano banana” → treat as Gemini/Imagen image model on Vertex)

Video: Runway or Pika (Veo3 not publicly available)
UX: Single app with tabs: Chat, Images, Videos, CV Maker, Slide Maker. A Model dropdown appears where relevant.
Auth: Google OAuth only at first (to avoid email domain setup).
Payments: Manual verification first (bank transfer & admin toggle), later add PayPal/HyperPay adapters.
Metering: Per-plan monthly quotas (3/4/5 JOD tiers), token count (chat), image count, video seconds, export limits.
Logging: Append every major step (success/error) to docs/ACTIVITY.md. Update build_checklist.json as tasks complete.
Non-negotiables: Input validation, rate limiting, robust error paths, secrets in AWS Secrets Manager (never in Git).

Phase 0 — Repo Bootstrap (Monorepo, Tooling, Guardrails)

Goal: Create a production-ready monorepo scaffold with CI/CD, Docker, basic docs, and guardrails.

Tasks (do in order):

Initialize repo

Create top-level structure:

/apps
  /web          # Next.js (TypeScript) – UI
  /api          # FastAPI (Python) – provider orchestration, metering, exports
  /workers      # Node worker or Python worker for async jobs (video queue)
/infra
  /terraform    # IaC for AWS (modules for vpc, ec2, rds, s3, sqs, secrets)
    /modules/{vpc, ec2, rds, s3, sqs, secrets, ecr}
/packages
  /shared       # Shared TS types & utils (OpenAPI client, plan definitions)
/docs
  ACTIVITY.md
build_checklist.json
.github/workflows/{ci.yml, deploy.yml}
.editorconfig
.gitignore
LICENSE
README.md


Populate README.md with a 1-page overview + local dev quickstart.

Create docs/ACTIVITY.md with a section “Cursor activity log” and append a timestamped entry for every change you make.

Create build_checklist.json (see template below).

Tooling & Quality

Prettier + ESLint for TS, Ruff + Black for Python.

Commit hooks (Husky) to lint/format.

Conventional commits and release-please (optional) for tagging.

Docker

apps/web/Dockerfile (Next.js standalone build), apps/api/Dockerfile (FastAPI + Uvicorn), apps/workers/Dockerfile.

Root docker-compose.dev.yml for local multi-container dev.

CI

ci.yml: lint, type-check, build Docker images.

deploy.yml: on tag → build/push to ECR and trigger remote deploy on EC2.

Acceptance:

pnpm dev (for web) and uvicorn (for api) run locally with docker compose.

First CI green; docs/ACTIVITY.md shows your steps; build_checklist.json updated.

build_checklist.json template:

{
  "phase": 0,
  "items": [
    {"id": "repo_scaffold", "title": "Repo scaffold created", "status": "todo"},
    {"id": "tooling_qc", "title": "Lint/formatters/hooks", "status": "todo"},
    {"id": "dockerized", "title": "Dockerfiles and compose", "status": "todo"},
    {"id": "ci_setup", "title": "GitHub Actions CI", "status": "todo"}
  ],
  "last_updated": ""
}

Phase 1 — Minimal AWS Infra (Terraform) & Secrets

Goal: Provision the smallest viable AWS footprint via Terraform.

Architecture (minimal cost):

VPC (two subnets), Security Groups

EC2 t3.micro (Amazon Linux 2023) running Docker Compose (reverse proxy Nginx + web + api + worker).

RDS Postgres (db.t4g.micro) for auth, plans, metering.

S3 for user exports (PDFs, PPTX, images/video outputs) + presigned URLs.

SQS queue for video jobs.

Secrets Manager for all API keys (OpenAI, Anthropic, Vertex SA JSON, Runway/Pika, OAuth secrets).

ECR for container images.

Tasks:

infra/terraform/modules/* — write reusable modules for vpc, ec2, rds, s3, sqs, ecr, secrets.

infra/terraform/environments/dev — compose modules; outputs: EC2 public DNS, DB endpoint, bucket name, queue URL, ECR repos.

User data on EC2 to install Docker, pull images, and run docker compose from /srv/pulse.

Create Secrets Manager placeholders (no secrets committed).

Acceptance:

terraform apply creates resources w/ outputs.

You can SSH to EC2, Docker is installed, Nginx returns a health page.

Phase 2 — Auth, Users, Plans, Metering (API & DB)

Goal: Set up core backend (FastAPI) with Postgres models for users, plans, usage metering, admin toggles.

DB schema (Alembic migrations):

users(id, email, name, auth_provider, created_at, is_admin)

plans(id, name, monthly_price_jod, chat_tokens, image_creations, video_seconds, cv_exports, slide_exports, is_active)

subscriptions(id, user_id, plan_id, status, period_start, period_end, payment_method, manual_verified_by)

usage_events(id, user_id, feature, model, input_tokens, output_tokens, image_count, video_seconds, bytes, cost_estimate, created_at)

jobs(id, user_id, type, payload_json, status, progress, result_url, created_at, updated_at) // for video/image long tasks

admin_flags(id, key, value_json, updated_at) // e.g., maintenance mode, free trial toggles

Auth:

Google OAuth only (Supabase/Clerk avoided to keep AWS-native; use OAuth flow handled by Next.js + API with sessions via JWT stored HttpOnly).

Store minimal user profile on first login.

API endpoints (OpenAPI documented):

/auth/google/start, /auth/google/callback

/me, /plans, /subscribe/manual, /admin/verify-subscription/:id

/usage/summary, /usage/events

Shared middleware: rate limiting, plan enforcement.

Acceptance:

Sign in with Google works.

Admin can mark a subscription as paid (manual).

Usage events recorded for test calls.

Phase 3 — Provider Layer & Chat

Goal: Unified provider abstraction + Chat completion endpoint.

Provider interfaces (apps/api/app/providers/*):

openai_provider.py (chat)

anthropic_provider.py (chat)

google_vertex_provider.py (chat via Gemini on Vertex AI; REST w/ service account)

Common types.py & router_chat.py:

POST /chat/complete: {message[], system?, model, temperature, ...} → streams tokens; counts tokens → emits usage_events.

Secrets (via AWS Secrets Manager):

OPENAI_API_KEY, ANTHROPIC_API_KEY

GCP_VERTEX_PROJECT_ID, GCP_VERTEX_LOCATION, GCP_VERTEX_SA_JSON (base64 of service account key)

Decrypt/resolve at container start; never log secrets.

Web (Next.js):

/chat page with:

Model dropdown: OpenAI, Anthropic, Google

System prompt text area (optional), temperature slider

Token counter, monthly quota progress

Streaming UI

Acceptance:

Can chat with any of the 3 providers and see quotas decrement.

Phase 4 — Image Generation (Vertex AI Imagen)

Goal: Image generation with model picker (default: Vertex Imagen); count image generations; store to S3.

API:

POST /image/generate → {prompt, model, size, count}

If provider = google, call Vertex Imagen REST (text-to-image, imagefx/imagen endpoint per 2025 API).

Optional: OpenAI image as a fallback.

Validate prompt length; return presigned S3 URLs.

Web:

/images page:

Prompt box, seed/size, Model dropdown (Google default; OpenAI fallback)

Grid of generated images + “Save to S3” + “Download”

Usage bar (images remaining)

Acceptance:

Generates images, saves to S3, records usage_events with image_count.

Phase 5 — Video Generation (Runway/Pika) + Jobs (SQS)

Goal: Async video generation via provider adapters, with SQS queue and worker.

Flow:

POST /video/generate → enqueue job {prompt, style, seconds, provider}; check plan’s video_seconds remaining.

Worker polls SQS, calls Runway/Pika API, polls for completion, uploads final MP4 to S3, updates jobs row.

Client polls /jobs/:id or uses SSE /jobs/stream.

Web:

/videos: Prompt, duration (defaults 4–8s), Provider dropdown (Runway/Pika), progress states, final download link.

Acceptance:

End-to-end job lifecycle works; video_seconds decremented.

Phase 6 — CV Maker (Export DOCX/PDF)

Goal: Simple CV builder with structured form → generate DOCX and PDF.

Implementation:

Frontend form sections (Personal, Summary, Experience, Skills, Education).

API creates DOCX via python-docx templates; for PDF, render HTML with Jinja + headless Chromium (Playwright) → PDF.

Store to S3, return presigned URLs; count cv_exports.

Acceptance:

User can create CV, export DOCX/PDF; files persist in S3; quotas enforced.

Phase 7 — Slide Maker (Export PPTX/PDF)

Goal: Slide generator from outline or topic.

Implementation:

Frontend: input topic or outline; optional “auto-outline” (LLM call).

Backend: generate content via chat provider; build PPTX with PptxGenJS (run in Node worker or server) or Python python-pptx.

Export PPTX; optional PDF via Chromium. Count slide_exports.

Acceptance:

PPTX downloads, looks decent, fonts embedded; quotas enforced.

Phase 8 — Plans, Quotas, Admin Dashboard, Payments (Manual now, PayPal later)

Goal: Turn on the business layer.

Plans (seed in DB):

Starter (3 JOD) — e.g., 50k chat tokens, 20 images, 30 video seconds, 1 CV, 1 Slide export

Plus (4 JOD) — higher limits

Pro (5 JOD) — highest limits
(Tune later; make server-side constants so changing plan updates limits next cycle.)

Admin:

/admin page: users, subscriptions, manual verify button, usage search, job monitor.

Payments:

Manual: /subscribe/manual issues invoice ref; admin toggles verified.

Adapters: Provide interfaces for PayPal & HyperPay; keep feature-flagged off until configured.

Acceptance:

Users can pick a plan, be marked paid, and limits apply immediately.

Phase 9 — Observability, Security, Rate Limits

Goal: Be safe and observable.

Tasks:

Structured logs (JSON) to stdout; Nginx access logs.

Basic tracing (OpenTelemetry) between web ↔ api ↔ worker.

Rate limiting (per IP + per user).

Input validation with Pydantic + Zod.

CSP, CSRF, secure cookies, HTTPS (when domain added).

Backup script for RDS snapshots nightly (Terraform + event rule).

Acceptance:

Logs visible, rate limits tested, snapshot rules present.

Phase 10 — Deploy to AWS (ECR → EC2 via Compose)

Goal: CI/CD path from GitHub to AWS.

Tasks:

GitHub Actions builds images, pushes to ECR, then SSH to EC2 to:

Pull latest images,

Write .env from Secrets Manager values (rendered by a small bootstrap script),

docker compose up -d --remove-orphans.

Health checks pass; app reachable on EC2 public DNS.

Acceptance:

Green deploy, services healthy, real traffic works.

Frontend Details (Next.js + Tailwind + shadcn/ui)

Routes:
/ (dashboard), /chat, /images, /videos, /cv, /slides, /account, /admin
Components:

ModelPicker (provider + model dropdown)

QuotaBar (feature-specific)

JobProgress (for videos)

ExportCard (download/share)

Style: Clean, minimal, tabs top; clear quotas and plan CTAs.

Environment & Secrets (load from AWS Secrets Manager at runtime)

Secrets to create (names you must use):

OPENAI_API_KEY

ANTHROPIC_API_KEY

GCP_VERTEX_PROJECT_ID

GCP_VERTEX_LOCATION (e.g., us-central1)

GCP_VERTEX_SA_JSON (base64 of service account JSON)

RUNWAY_API_KEY and/or PIKA_API_KEY

GOOGLE_OAUTH_CLIENT_ID, GOOGLE_OAUTH_CLIENT_SECRET

POSTGRES_URL (from RDS)

S3_BUCKET_NAME, AWS_REGION

SQS_QUEUE_URL

JWT_SECRET

Never commit secrets. API containers should read from env that your bootstrap script resolves from Secrets Manager on start.

Vertex AI (Google) — How to get credentials (for images/chat)

In Google Cloud Console: create a Project → enable Vertex AI API.

Create a Service Account, grant roles: Vertex AI User, Storage Object Viewer.

Create a Key (JSON); download; base64 encode it locally.

In AWS Secrets Manager, set GCP_VERTEX_SA_JSON to that base64 string; set GCP_VERTEX_PROJECT_ID and GCP_VERTEX_LOCATION.

API code: use SA JWT to call Vertex endpoints (Imagen for image; Gemini for chat) over REST.

(You asked earlier about “Vertx AI keys”: this is the flow—no classic “API key”, use service account credentials.)

Nginx & Runtime Topology (on EC2)

:80 → Nginx →

/ → web:3000

/api/* → api:8000 (FastAPI)

/sse/* → api:8000 (keep-alive, tuned timeouts)

workers run headless; connect to SQS and S3.

Rate Limits & Quotas (examples)

Per-user: 60 req/min to /chat/complete + daily caps,

Per-IP: 120 req/min overall,

Quotas from plans enforced before calling providers; return 402 Plan limit exceeded JSON when out.

Error Budget & Risks (reality check)

Timeline: Even with Cursor, this is ~3–4 weeks for a robust v1. Trying to do all five tools in 1 day will break quality and burn time later.

Costs: RDS + EC2 + S3 + ECR + SQS should stay low on micro tiers, but video jobs and image gen can spike provider bills—keep strict quotas.

Model drift/availability: Veo3 unavailable; rely on Runway/Pika adapters.

Payments in Jordan: Start manual or PayPal; HyperPay integration can come after traction.

Admin Playbook

Toggle free trial days in admin_flags.

View job queue health and requeue failed jobs.

Manually verify payments during MVP.

Adjust plans server-side only (immutable history for past subscriptions).

Local Dev Quickstart (for README)
# 1) Prereqs
pnpm i --frozen-lockfile
python -m venv .venv && source .venv/bin/activate && pip install -r apps/api/requirements.txt

# 2) Start dev stack
docker compose -f docker-compose.dev.yml up --build

# 3) Seed DB
alembic upgrade head && python apps/api/scripts/seed_plans.py

# 4) Visit
open http://localhost:3000

Minimal .env.example (local only; prod uses Secrets Manager)
NODE_ENV=development
NEXT_PUBLIC_API_BASE=http://localhost:8000
JWT_SECRET=replace_me_local_only
POSTGRES_URL=postgresql://user:pass@localhost:5432/pulse
S3_BUCKET_NAME=pulse-dev-exports
AWS_REGION=eu-central-1
SQS_QUEUE_URL=http://localstack:4566/000000000000/pulse-jobs
OPENAI_API_KEY=sk-XXX
ANTHROPIC_API_KEY=... 
GOOGLE_OAUTH_CLIENT_ID=...
GOOGLE_OAUTH_CLIENT_SECRET=...
GCP_VERTEX_PROJECT_ID=your-project
GCP_VERTEX_LOCATION=us-central1
GCP_VERTEX_SA_JSON=base64-blob
RUNWAY_API_KEY=...
PIKA_API_KEY=...

What to build first (exact Cursor order of operations)

Phase 0: scaffold repo, add CI, Docker, checklist/logging.

Phase 1: Terraform modules (VPC, EC2, RDS, S3, SQS, ECR, Secrets). terraform apply and record outputs.

Phase 2: FastAPI + Postgres + OAuth (Google) + plans/usage models + admin endpoints.

Phase 3: Chat provider adapters + streaming + token accounting + UI chat page.

Phase 4: Image gen via Vertex (Imagen) + S3 storage + UI page.

Phase 5: SQS jobs + worker + Runway/Pika adapters + video page.

Phase 6: CV maker (DOCX/PDF) + quotas.

Phase 7: Slide maker (PPTX/PDF) + quotas.

Phase 8: Admin dashboard + manual payments + PayPal adapter (flagged off).

Phase 9: Observability, rate limits, backups.

Phase 10: CI/CD to ECR + deploy to EC2 w/ docker compose + health checks.

Each time you complete a sub-task, append a line to docs/ACTIVITY.md with date/time, what changed, and any errors/fixes, and update the relevant item in build_checklist.json from "todo" → "doing" → "done" (refresh the last_updated timestamp).

Acceptance Test Matrix (short)

Auth: Login via Google; no account → auto create; session persists.

Plans: Switching plan updates quotas next cycle; over-limit returns 402.

Chat: Providers switch correctly; token accounting sensible ±5%.

Images: Vertex call works; S3 links valid for 15 min; usage increments.

Videos: Job queued → running → success; retries on 5xx; usage decremented by seconds.

CV/Slides: Exports both DOCX/PDF/PPTX; files < 10 MB; Arabic text acceptable but not required.

Infra: EC2 low CPU at idle; RDS snapshots created; Secrets never logged.

Security: Rate limits enforced; CSP header present; cookies HttpOnly/SameSite=Lax.